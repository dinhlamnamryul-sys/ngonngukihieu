import streamlit as st
import cv2
import mediapipe as mp
import os
import tempfile
import time
from unidecode import unidecode
from gtts import gTTS
from PIL import Image
import numpy as np

# --- C·∫•u h√¨nh MediaPipe ---
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)
drawing_utils = mp.solutions.drawing_utils

# Style v·∫Ω
pose_style = drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)
hand_style = drawing_utils.DrawingSpec(color=(255, 0, 0), thickness=1, circle_radius=1)

# --- H√†m Ti·ªán √çch ---
def process_frame(frame):
    """X·ª≠ l√Ω nh·∫≠n di·ªán t∆∞ th·∫ø v√† tay tr√™n m·ªôt khung h√¨nh"""
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # X·ª≠ l√Ω nh·∫≠n di·ªán
    results_pose = pose.process(frame_rgb)
    results_hands = hands.process(frame_rgb)
    
    # V·∫Ω k·∫øt qu·∫£
    if results_pose.pose_landmarks:
        drawing_utils.draw_landmarks(frame_rgb, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS, pose_style, pose_style)
    if results_hands.multi_hand_landmarks:
        for hand_landmarks in results_hands.multi_hand_landmarks:
            drawing_utils.draw_landmarks(frame_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS, hand_style, hand_style)
            
    return frame_rgb

def play_audio_st(text):
    """T·∫°o v√† ph√°t √¢m thanh trong Streamlit"""
    tts = gTTS(text=f"C√¢u n√≥i l√†: {text}", lang='vi')
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        st.audio(fp.name, format="audio/mp3")

# --- Giao Di·ªán Streamlit ---
st.set_page_config(page_title="NG√îN NG·ªÆ K√ù HI·ªÜU AI", layout="centered")
st.title("ü§ü NG√îN NG·ªÆ K√ù HI·ªÜU AI")

# Sidebar - C·∫•u h√¨nh t√¨m ki·∫øm
st.sidebar.header("C√†i ƒë·∫∑t t√¨m ki·∫øm")
chude_options = ["T·∫•t c·∫£", "ƒë·ªì d√πng h·ªçc t·∫≠p", "ƒë·ªông v·∫≠t", "gia ƒë√¨nh", "giao th√¥ng", "tr√°i c√¢y"]
selected_chude = st.sidebar.selectbox("Ch·ªçn ch·ªß ƒë·ªÅ", chude_options)

# Khu v·ª±c nh·∫≠p li·ªáu
col1, col2 = st.columns([3, 1])
with col1:
    search_query = st.text_input("Nh·∫≠p c√¢u n√≥i ho·∫∑c ch·ªØ c√°i:", "")
with col2:
    search_btn = st.button("T√¨m ki·∫øm")

# Khu v·ª±c hi·ªÉn th·ªã Video/·∫¢nh
display_area = st.empty()

# X·ª≠ l√Ω Logic T√¨m ki·∫øm
if search_btn and search_query:
    name_search = unidecode(search_query).lower().strip()
    folders = ["video_train", "anh_train", "ƒë·ªì d√πng h·ªçc t·∫≠p", "ƒë·ªông v·∫≠t", "gia ƒë√¨nh", "giao th√¥ng", "tr√°i c√¢y"] if selected_chude == "T·∫•t c·∫£" else [selected_chude]
    
    found = False
    for folder in folders:
        if os.path.exists(folder):
            for file in os.listdir(folder):
                file_name_clean = unidecode(os.path.splitext(file)[0]).lower().strip()
                
                if name_search == file_name_clean:
                    file_path = os.path.join(folder, file)
                    found = True
                    
                    # Ph√°t √¢m thanh
                    play_audio_st(os.path.splitext(file)[0])
                    
                    # X·ª≠ l√Ω Video
                    if file.lower().endswith(('.mp4', '.avi', '.mkv')):
                        cap = cv2.VideoCapture(file_path)
                        st_frame = st.empty() # Placeholder cho video
                        
                        while cap.isOpened():
                            ret, frame = cap.read()
                            if not ret: break
                            
                            # X·ª≠ l√Ω v√† hi·ªÉn th·ªã
                            processed_frame = process_frame(frame)
                            st_frame.image(processed_frame, channels="RGB", use_container_width=True)
                            time.sleep(0.01) # Gi·∫£m t·ªëc ƒë·ªô ƒë·ªÉ gi·ªëng video th·∫≠t
                        cap.release()
                        
                    # X·ª≠ l√Ω ·∫¢nh
                    elif file.lower().endswith(('.png', '.jpg', '.jpeg')):
                        img = Image.open(file_path)
                        st.image(img, caption=file, use_container_width=True)
                    break
        if found: break
    
    if not found:
        st.error("Kh√¥ng t√¨m th·∫•y ng√¥n ng·ªØ k√Ω hi·ªáu n√†o ph√π h·ª£p!")

# Ch·ª©c nƒÉng ch·∫°y file nh·∫≠n di·ªán ngo√†i (Subprocess)
st.divider()
if st.button("Ch·∫°y Nh·∫≠n Di·ªán Tay (C·ª≠a s·ªï ri√™ng)"):
    try:
        # L∆∞u √Ω: Subprocess s·∫Ω m·ªü camera tr√™n m√°y ch·ªß ƒëang ch·∫°y script
        import subprocess
        subprocess.Popen(['python', 'nhandientay.py'])
        st.success("ƒêang kh·ªüi ƒë·ªông c·ª≠a s·ªï nh·∫≠n di·ªán...")
    except Exception as e:
        st.error(f"L·ªói: {e}")

# Ch·ª©c nƒÉng Upload Video s·∫µn c√≥
st.sidebar.divider()
uploaded_file = st.sidebar.file_uploader("Ho·∫∑c t·∫£i l√™n video ƒë·ªÉ ph√¢n t√≠ch", type=["mp4", "avi", "mkv"])
if uploaded_file:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    
    cap = cv2.VideoCapture(tfile.name)
    st_frame_upload = st.empty()
    
    if st.sidebar.button("B·∫Øt ƒë·∫ßu ph√¢n t√≠ch"):
        play_audio_st(os.path.splitext(uploaded_file.name)[0])
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            processed_frame = process_frame(frame)
            st_frame_upload.image(processed_frame, channels="RGB", use_container_width=True)
        cap.release()
