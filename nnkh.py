import streamlit as st
import os
from PIL import Image
from gtts import gTTS
import uuid
from unidecode import unidecode
import speech_recognition as sr

# ==============================
# C·∫§U H√åNH
# ==============================
DATA_DIR = "data"

HMONG_DICT = {
    "xin ch√†o": "nyob zoo",
    "gia ƒë√¨nh": "tsev neeg",
    "ƒë·ªông v·∫≠t": "tsiaj",
    "tr√°i c√¢y": "txiv hmab txiv ntoo",
    "a": "a",
    "ƒë": "ƒë",
    "0": "xoom",
    "1": "ib",
    "2": "ob"
}

# ==============================
# AI CORE (T·ª∞ PH√ÇN BI·ªÜT)
# ==============================
def ai_recognize(image):
    """
    AI gi·∫£ l·∫≠p ‚Äì thay b·∫±ng model th·∫≠t sau
    """
    return "A"   # v√≠ d·ª• raw label

def ai_postprocess(label):
    """
    T·ª± ph√¢n bi·ªát ch·ªØ / s·ªë / t·ª´
    """
    for folder in os.listdir(DATA_DIR):
        if label in os.listdir(os.path.join(DATA_DIR, folder)):
            return folder, label
    return "unknown", label

# ==============================
# T√åM MEDIA
# ==============================
def find_media(label):
    label_norm = unidecode(label).lower()

    for folder in os.listdir(DATA_DIR):
        folder_path = os.path.join(DATA_DIR, folder)
        for file in os.listdir(folder_path):
            name = os.path.splitext(file)[0]
            if unidecode(name).lower() == label_norm:
                return os.path.join(folder_path, file)
    return None

# ==============================
# TTS
# ==============================
def speak(text):
    file = f"tts_{uuid.uuid4().hex}.mp3"
    gTTS(text=text, lang="vi").save(file)
    st.audio(file)
    os.remove(file)

# ==============================
# TRANSLATE
# ==============================
def translate(text, lang):
    if lang == "Ti·∫øng M√¥ng":
        return HMONG_DICT.get(text.lower(), text)
    return text

# ==============================
# STREAMLIT UI
# ==============================
st.set_page_config("NNKH AI", layout="wide")
st.title("ü§ü NG√îN NG·ªÆ K√ù HI·ªÜU AI ‚Äì T·ª∞ PH√ÇN BI·ªÜT")

lang = st.selectbox("Ng√¥n ng·ªØ xu·∫•t", ["Ti·∫øng Vi·ªát", "Ti·∫øng M√¥ng"])

st.subheader("üì∑ Camera")

img_file = st.camera_input("B·∫≠t camera")

if img_file:
    img = Image.open(img_file)

    raw_label = ai_recognize(img)
    category, label = ai_postprocess(raw_label)

    label = translate(label, lang)

    st.success(f"AI nh·∫≠n di·ªán: {label} ({category})")

    media = find_media(label)
    if media:
        st.video(media)

    speak(label)

# ==============================
# VOICE SEARCH
# ==============================
st.subheader("üéôÔ∏è T√¨m ki·∫øm b·∫±ng gi·ªçng n√≥i")

audio = st.audio_input("N√≥i")

if audio:
    r = sr.Recognizer()
    with sr.AudioFile(audio) as src:
        text = r.recognize_google(r.record(src), language="vi-VN")

    st.info(f"B·∫°n n√≥i: {text}")
    media = find_media(text)
    if media:
        st.video(media)
