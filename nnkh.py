import streamlit as st
import cv2
import mediapipe as mp
import math
import numpy as np
import av  # Th∆∞ vi·ªán x·ª≠ l√Ω video frame quan tr·ªçng
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
import time
from datetime import datetime

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="Sign.AI - D·ªãch thu·∫≠t Ng√¥n ng·ªØ K√Ω hi·ªáu",
    page_icon="‚úã",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- KH·ªûI T·∫†O SESSION STATE (Gi·∫£ l·∫≠p Database) ---
if 'user' not in st.session_state:
    st.session_state.user = {'name': 'Anonymous', 'role': 'user'}
if 'media_bank' not in st.session_state:
    st.session_state.media_bank = []
if 'detected_text' not in st.session_state:
    st.session_state.detected_text = ""

# --- CSS T√ôY CH·ªàNH ---
st.markdown("""
<style>
    .main { background-color: #fcfdfe; color: #0f172a; }
    [data-testid="stSidebar"] { background-color: #0f172a; color: white; }
    div.stButton > button {
        border-radius: 1rem; font-weight: bold; text-transform: uppercase;
    }
</style>
""", unsafe_allow_html=True)

# --- LOGIC X·ª¨ L√ù ·∫¢NH (MEDIAPIPE) ---
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

class HandGestureProcessor(VideoProcessorBase):
    def __init__(self):
        # Kh·ªüi t·∫°o model MediaPipe
        self.hands = mp_hands.Hands(
            max_num_hands=1,
            model_complexity=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.7
        )
        self.last_letter = ""
        self.stability_counter = 0

    def analyze_hand_gesture(self, landmarks):
        lm = landmarks.landmark
        
        def dist(p1, p2):
            return math.sqrt((lm[p1].x - lm[p2].x)**2 + (lm[p1].y - lm[p2].y)**2)
        
        def is_ext(tip, pip):
            return lm[tip].y < lm[pip].y

        # Logic nh·∫≠n di·ªán ƒë∆°n gi·∫£n h√≥a
        thumb_ext = lm[4].x < lm[3].x
        index_ext = is_ext(8, 6)
        middle_ext = is_ext(12, 10)
        ring_ext = is_ext(16, 14)
        pinky_ext = is_ext(20, 18)

        # Logic mapping (nh∆∞ code c≈©)
        if not index_ext and not middle_ext and not ring_ext and not pinky_ext and lm[4].y < lm[6].y: return "A"
        if index_ext and middle_ext and ring_ext and pinky_ext and dist(8, 12) < 0.04: return "B"
        if index_ext and not middle_ext and not ring_ext and not pinky_ext: return "D" # V√≠ d·ª• r√∫t g·ªçn
        if pinky_ext and not index_ext: return "I"
        if index_ext and middle_ext and not ring_ext: return "V"
        if dist(8, 4) < 0.05 and dist(12, 4) < 0.05: return "O"
        
        return "" # Tr·∫£ v·ªÅ r·ªóng n·∫øu kh√¥ng kh·ªõp

    def recv(self, frame):
        # 1. Chuy·ªÉn ƒë·ªïi t·ª´ av.VideoFrame sang numpy array (OpenCV format)
        img = frame.to_ndarray(format="bgr24")
        
        # 2. X·ª≠ l√Ω ·∫£nh (Mirror -> RGB -> MediaPipe)
        img = cv2.flip(img, 1)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.hands.process(img_rgb)
        
        detected_char = ""

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # V·∫Ω khung x∆∞∆°ng tay
                mp_drawing.draw_landmarks(
                    img, 
                    hand_landmarks, 
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=4),
                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                )
                
                # Ph√¢n t√≠ch c·ª≠ ch·ªâ
                detected_char = self.analyze_hand_gesture(hand_landmarks)
                
                if detected_char:
                    # Logic ·ªïn ƒë·ªãnh (Debounce)
                    if detected_char == self.last_letter:
                        self.stability_counter += 1
                    else:
                        self.last_letter = detected_char
                        self.stability_counter = 0

                    # Hi·ªÉn th·ªã ch·ªØ l√™n m√†n h√¨nh
                    cv2.putText(img, f"Ky tu: {detected_char}", (30, 80), 
                                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 4, cv2.LINE_AA)
                    
                    # Thanh ti·∫øn tr√¨nh x√°c nh·∫≠n
                    bar_width = int((self.stability_counter / 20) * 200)
                    cv2.rectangle(img, (30, 100), (30 + bar_width, 120), (0, 255, 0), -1)

        # 3. QUAN TR·ªåNG: Chuy·ªÉn ƒë·ªïi ng∆∞·ª£c t·ª´ numpy array v·ªÅ av.VideoFrame
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# --- DANH M·ª§C ---
CATEGORIES = [
    {"id": "all", "label": "T·∫•t c·∫£"},
    {"id": "alphabet", "label": "B·∫£ng ch·ªØ c√°i"},
    {"id": "communication", "label": "Giao ti·∫øp c∆° b·∫£n"},
    {"id": "school", "label": "ƒê·ªì d√πng h·ªçc t·∫≠p"},
]

# --- UI CH√çNH ---
with st.sidebar:
    st.title("‚úã Sign.AI")
    menu = st.radio("Menu", ["D·ªãch thu·∫≠t AI", "Th∆∞ vi·ªán K√Ω hi·ªáu", "Qu·∫£n tr·ªã Admin"])

if menu == "D·ªãch thu·∫≠t AI":
    st.header("D·ªãch Thu·∫≠t Camera")
    st.write("B·∫≠t camera v√† ƒë∆∞a tay v√†o khung h√¨nh.")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # WebRTC Streamer
        webrtc_streamer(
            key="sign-detection",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=HandGestureProcessor, # S·ª≠ d·ª•ng class x·ª≠ l√Ω m·ªõi
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

    with col2:
        st.info("üí° H∆∞·ªõng d·∫´n: Gi·ªØ y√™n tay kho·∫£ng 1 gi√¢y ƒë·ªÉ h·ªá th·ªëng ch·ªët ch·ªØ c√°i.")

elif menu == "Th∆∞ vi·ªán K√Ω hi·ªáu":
    st.header("Th∆∞ vi·ªán")
    search = st.text_input("T√¨m ki·∫øm")
    
    if st.session_state.media_bank:
        for item in st.session_state.media_bank:
            if search.lower() in item['name'].lower():
                with st.expander(f"{item['name']} ({item['category']})"):
                    if item['type'] == 'image':
                        st.image(item['data'])
                    else:
                        st.video(item['data'])
    else:
        st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu. H√£y v√†o Admin ƒë·ªÉ th√™m.")

elif menu == "Qu·∫£n tr·ªã Admin":
    st.header("Upload D·ªØ Li·ªáu")
    
    with st.form("upload"):
        name = st.text_input("T√™n k√Ω hi·ªáu")
        cat = st.selectbox("Danh m·ª•c", [c['label'] for c in CATEGORIES])
        file = st.file_uploader("File ·∫£nh/video")
        submit = st.form_submit_button("L∆∞u")
        
        if submit and file and name:
            ftype = 'video' if 'video' in file.type else 'image'
            st.session_state.media_bank.append({
                "name": name,
                "category": cat,
                "type": ftype,
                "data": file.read()
            })
            st.success("ƒê√£ l∆∞u th√†nh c√¥ng!")
